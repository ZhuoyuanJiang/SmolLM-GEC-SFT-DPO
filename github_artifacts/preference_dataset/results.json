{
  "config": {
    "sft_model_path": "experiments/sft_padding_bs16_lr8e-05_ep1/final_model",
    "dataset_name": "grammarly/coedit",
    "batch_size": 128,
    "generation_configs": {
      "config_1": {
        "max_new_tokens": 128,
        "temperature": 0.3,
        "do_sample": true,
        "top_p": 0.7,
        "repetition_penalty": 1.05
      },
      "config_2": {
        "max_new_tokens": 128,
        "temperature": 0.7,
        "do_sample": true,
        "top_p": 0.9,
        "repetition_penalty": 1.15
      }
    },
    "filtering": {
      "min_edit_distance_diff": 2,
      "max_length_ratio": 3.0,
      "min_length_ratio": 0.33
    },
    "seed": 42
  },
  "metrics": {
    "final_dataset_size": 18782,
    "processing_time": 725.594426,
    "total_processed": 19823,
    "successful": 18782,
    "skipped_identical": 448,
    "skipped_empty": 0,
    "skipped_small_diff": 567,
    "skipped_length_ratio": 26,
    "total_chosen_dist": 121217,
    "total_rejected_dist": 677243
  },
  "system": {
    "gpu": "NVIDIA GeForce RTX 3090",
    "cuda_version": "12.4",
    "pytorch_version": "2.5.1+cu124",
    "timestamp": "2025-08-05T13:50:44.093722"
  }
}